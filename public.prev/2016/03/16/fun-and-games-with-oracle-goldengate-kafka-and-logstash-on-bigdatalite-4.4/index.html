<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4</title>
		<link rel="alternate" type="application/rss+xml" title="RSS" href="https://rmoff.github.io/index.xml">
		<link rel="canonical" href="https://rmoff.github.io/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/">
		
		<link rel="shortcut icon" type="image/png" href="https://rmoff.github.io/apple-touch-icon-precomposed.png">
		
		
		<meta name="generator" content="Hugo 0.52" />

		
		<meta name="og:title" content="Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4" />
		<meta name="og:type" content="article" />
		<meta name="og:image" content="https://rmoff.github.io/images/2016/03/2016-03-16_23-12-54.png" />
		<meta name="og:description" content="" />
		<meta name="og:url" content="https://rmoff.github.io/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/" />
		<meta name="og:site_name" content="Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@" />


		
		<link rel="stylesheet" href="https://rmoff.github.io/css/tachyons.min.css" />
		<link rel="stylesheet" href="https://rmoff.github.io/css/story.css" />
		<link rel="stylesheet" href="https://rmoff.github.io/css/descartes.css" />
		
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
		<link href="https://fonts.googleapis.com/css?family=Quattrocento+Sans:400,400i,700,700i|Quattrocento:400,700|Spectral:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
		

		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
		
		<script src="https://rmoff.github.io/js/story.js"></script>

	</head>
	<body class="ma0 bg-white section-post page-kind-page is-page-true ">
		
		<header class="cover bg-top" style="background-image: url('https://rmoff.github.io/images/2016/03/2016-03-16_23-12-54.png'); background-position: center;">
			<div class="bg-black-30 bb bt">

				<nav class="hide-print sans-serif  border-box pa3 ph5-l">
					<a href="https://rmoff.github.io" title="Home">
						<img src="https://rmoff.github.io/img/logo.jpg" class="w2 h2 br-100" alt="rmoff&#39;s random ramblings" />
					</a>
					<div class="fr h2 pv2 tr">
						<a class="link f5 ml2 dim near-white" href="/about-me/">about</a>
						<a class="link f5 ml2 dim near-white" href="/talks/">talks</a>
						<a class="link f5 ml2 dim near-white" href="https://github.com/rmoff/"><i class="fab fa-github-square"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://www.linkedin.com/in/robinmoffatt/"><i class="fab fa-linkedin"></i></a>
						<a class="link f5 ml2 dim near-white" href="https://twitter.com/rmoff/"><i class="fab fa-twitter-square"></i></a>
						<a class="link f5 ml2 dim near-white fas fa-rss-square" href="https://rmoff.github.io/index.xml" title="RSS Feed"></a>
						<a class="link f5 ml2 dim near-white fas fa-search" href="https://rmoff.github.io/search/" role="search" title="Search"></a>
					</div>
				</nav>

				<div id="hdr" class="tc-l pv4-ns pv5-l pv2 ph3 ph4-ns">
					<h1 class="near-white mt1-ns f2 fw3 mb0 mt0 lh-title">Fun and Games with Oracle GoldenGate, Kafka, and Logstash on BigDataLite 4.4</h1>
					<h2 class="near-white mt3-l mb4-l fw1 f6 f3-l measure-wide-l center lh-copy mt2 mb3">
						
						
							
								Published
								<time datetime="2016-03-16T22:01:00Z">Mar 16, 2016</time>
								<span class="display-print">by Robin Moffatt</span>
								 in <a href="https://rmoff.github.io/categories//logstash" class="no-underline category near-white dim">Logstash</a>, <a href="https://rmoff.github.io/categories//kafka" class="no-underline category near-white dim">Kafka</a>, <a href="https://rmoff.github.io/categories//goldengate" class="no-underline category near-white dim">Goldengate</a>, <a href="https://rmoff.github.io/categories//avro" class="no-underline category near-white dim">Avro</a>, <a href="https://rmoff.github.io/categories//elasticsearch" class="no-underline category near-white dim">Elasticsearch</a>
								<span class="display-print">at https://rmoff.github.io/2016/03/16/fun-and-games-with-oracle-goldengate-kafka-and-logstash-on-bigdatalite-4.4/</span>
							
						
					</h2>
				</div>

				
				
				
				

			</div>
		</header>
		
		<main role="main">
		
<article class="center bg-white br-3 pv1 ph4 nested-copy-line-height lh-copy f4 nested-links mw-100 measure-wide">
	

<p>The Oracle by Example (ObE) <a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/fmw/odi/odi_12c/DI_BDL_Guide/BigDataIntegration_Demo.html?cid=10235&amp;ssid=0">here</a> demonstrating how to use <a href="[https://docs.oracle.com/goldengate/bd1221/gg-bd/GBDIN/intro_adapter.htm#GBDIN101](http://)">Goldengate to replicate transactions big data targets</a> such as HDFS is written for the BigDataLite <a href="http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite421-2843803.html">4.2.1</a>, and for me didn&rsquo;t work on the current latest version, <a href="http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite-2104726.html">4.4.0</a>.</p>

<p>The OBE (and similar <a href="http://www.oracle.com/webfolder/technetwork/odi/ODI_BigData_HOL.pdf">Hands On Lab</a> PDF) assume the presence of <code>pmov.prm</code> and <code>pmov.properties</code> in <code>/u01/ogg/dirprm/</code>. On BDL 4.4 there&rsquo;s only the extract to from Oracle configuration, <code>emov</code>.</p>

<p>Fortunately it&rsquo;s still possible to run this setup out of the box in BDL 4.4, with bells on because it includes <a href="http://kafka.apache.org/">Kafka</a> too. And, who doesn&rsquo;t like a bit of Kafka nowadays?</p>

<h3 id="getting-it-running">Getting it running</h3>

<ol>
<li><p>Set the Oracle extract running (as per the OBE/HOL instructions).</p>

<p><em>I&rsquo;m using the ever-awesome <code>rlwrap</code> so that if I mistype stuff in <code>ggsci</code> I can just arrow up/down to cycle through command history.</em></p>

<pre><code>[oracle@bigdatalite ~]$ cd /u01/ogg
[oracle@bigdatalite ogg]$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter for Oracle
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2_FBO
Linux, x64, 64bit (optimized), Oracle 12c on Nov 11 2015 03:53:23
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.



GGSCI (bigdatalite.localdomain) 1&gt; obey dirprm/bigdata.oby
</code></pre>

<p>Note that the output differs from the OBE/HOL screenshot, with only the <code>emov</code> extract listed now:</p>

<pre><code>GGSCI (bigdatalite.localdomain as system@cdb/CDB$ROOT) 9&gt; info all

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
EXTRACT     RUNNING     EMOV        04:00:10      00:00:01
</code></pre>

<p>Press <strong>Ctrl-D</strong> to exit <code>ggsci</code></p></li>

<li><p>Launch <code>ggsci</code> again, but from the <code>/u01/ogg-bd</code> folder this time. Run the same-named bigdata obey file, but note that it&rsquo;s a different set of instructions (because we&rsquo;re now in <code>/u01/ogg-bd</code>, rather than <code>/u01/ogg</code>)</p>

<pre><code>[oracle@bigdatalite ogg]$ cd /u01/ogg-bd
[oracle@bigdatalite ogg-bd]$ rlwrap ./ggsci

Oracle GoldenGate Command Interpreter
Version 12.2.0.1.0 OGGCORE_12.2.0.1.0_PLATFORMS_151101.1925.2
Linux, x64, 64bit (optimized), Generic on Nov 10 2015 16:18:12
Operating system character set identified as UTF-8.

Copyright (C) 1995, 2015, Oracle and/or its affiliates. All rights reserved.

GGSCI (bigdatalite.localdomain) 1&gt; obey dirprm/bigdata.oby
</code></pre>

<p>Looking at what&rsquo;s running we can see two replicats:</p>

<pre><code>GGSCI (bigdatalite.localdomain) 8&gt; INFO ALL

Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
REPLICAT    RUNNING     RKAFKA      00:00:00      00:00:01
REPLICAT    RUNNING     RMOV        00:00:00      00:00:02
</code></pre>

<p>Poking around the Kafka parameters we can see the configured topic for the transactions and schema. For full details about the Kafka handler <a href="https://docs.oracle.com/goldengate/bd1221/gg-bd/GADBD/kafka_handler.htm#GADBD449">see the documentation</a>.</p>

<pre><code>[oracle@bigdatalite ogg-bd]$ cat dirprm/kafka.props

gg.handlerlist = kafkahandler
gg.handler.kafkahandler.type = kafka
gg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.properties
gg.handler.kafkahandler.TopicName =oggtopic
gg.handler.kafkahandler.format =avro_op
gg.handler.kafkahandler.SchemaTopicName=mySchemaTopic
gg.handler.kafkahandler.BlockingSend =false
gg.handler.kafkahandler.includeTokens=false

gg.handler.kafkahandler.mode =tx
#gg.handler.kafkahandler.maxGroupSize =100, 1Mb
#gg.handler.kafkahandler.minGroupSize =50, 500Kb
</code></pre></li>
</ol>

<h3 id="testing-it-out">Testing it out</h3>

<p>Using the Kafka console shell we can observe what Oracle GoldenGate sends to Kafka:</p>

<pre><code>[oracle@bigdatalite dirprm]$ kafka-console-consumer --zookeeper localhost:2181 --topic oggtopic
</code></pre>

<p>In a separate session (or even better, in the same session but using <code>screen</code> as in the demo below) modify data in the <code>MOVIEDEMO.MOVIE</code> table on Oracle. You should see the change come through to Kafka after a few moments.</p>

<p><img src="/content/images/2016/03/ogg-kafka.gif" alt="" /></p>

<h4 id="always-rtfm">Always RTFM…</h4>

<blockquote>
<p>The manual? That thing that explains how things work, and what problems to watch out for? Yeah… about that…</p>
</blockquote>

<p>So I got the Kafka bit working above and was happy, it worked, it was neat. But, for the life of me I couldn&rsquo;t get the transactions to appear in Hive. They appeared in the HDFS file when I <code>hadoop fs -cat</code>&rsquo;d it, they showed up in the Hue data browser &hellip; but not in Hive. Was this some <a href="http://marcelkrcah.net/blog/how-newline-can-ruin-your-hive/">weird bug/issue</a> involving new lines? What was going on?</p>

<p>Here&rsquo;s what I saw in HDFS. Note the last line, 22:32:21:</p>

<pre><code>[oracle@bigdatalite ogg]$ sudo su - hdfs -c &quot;hadoop fs -cat /user/odi/hive/orcl.moviedemo.movie/*&quot;
D2016-03-16 22:14:47.0000001Foo201450000020000000give you up
D2016-03-16 22:14:47.0000002never gonna201450000020000000give you up
D2016-03-16 22:14:47.0000003never gonna201450000020000000give you up
D2016-03-16 22:14:47.0000004never gonna201450000020000000give you up
I2016-03-16 22:27:18.0000002Sharknadozz201450000020000000Flying sharks attack city
I2016-03-16 22:32:21.0000004242never gonna201450000020000000give you up
[oracle@bigdatalite ogg]$
</code></pre>

<p>And this is what I saw in Hive - only five of the six rows of data:</p>

<pre><code>hive&gt; select * from movie_updates;
OK
D       2016-03-16 22:14:47             1       Foo     2014    500000  20000000        give you up
D       2016-03-16 22:14:47             2       never gonna     2014    500000  20000000        give you up
D       2016-03-16 22:14:47             3       never gonna     2014    500000  20000000        give you up
D       2016-03-16 22:14:47             4       never gonna     2014    500000  20000000        give you up
I       2016-03-16 22:27:18             2       Sharknadozz     2014    500000  20000000        Flying sharks attack city
Time taken: 0.087 seconds, Fetched: 5 row(s)
</code></pre>

<p>​
Turns out <a href="https://docs.oracle.com/goldengate/bd1221/gg-bd/GADBD/hdfs_handler.htm#GADBD395">the manual</a> spells this out pretty darn clearly in a section cunningly named <strong>Common Pitfalls</strong> it notes that</p>

<blockquote>
<p>HDFS blocks under construction are not always visible to analytic tools.</p>
</blockquote>

<p>And since I&rsquo;m noodling around with a few rows of data here and there (nowhere near the 128MB HDFS block size), this was the very cause of my issue. A workaround to prove that I wasn&rsquo;t going mad? Restart the GoldenGate replicat with the <code>rmov.properties</code> file changed to close the HDFS file periodically:</p>

<pre><code>gg.handler.hdfs.fileRollInterval=30s
</code></pre>

<p>Obviously this has performance implications in a real-life implementation, but for proving out functionality, it saved me from complete insanity :-)</p>

<h3 id="sidenote-error-in-reset-bigdata-oby">Sidenote - error in reset_bigdata.oby?</h3>

<p>I might be missing something here, but it looks like there&rsquo;s a minor fubar in <code>/u01/ogg-bd/dirprm/reset_bigdata.oby</code>:</p>

<pre><code>start mgr
stop rmov
stop rkafka
shell sleep 5
delete rmov
stop rkafka
[...]
</code></pre>

<p>That second <code>stop rkafka</code> I&rsquo;m guessing should be <code>delete rkafka</code>?</p>

<h3 id="logstash">Logstash</h3>

<p>I&rsquo;m a long-time fan of the <a href="http://elastic.co">Elastic stack</a>, and Logstash has an input plugin for Kafka, so let&rsquo;s see if that can fit the jigsaw here too.</p>

<p>The data from GoldenGate is serialised using <a href="https://avro.apache.org/">Avro</a>. The schema is put by Goldengate onto a separate Kafka topic, <code>mySchemaTopic</code>. There&rsquo;s probably a more proper way to get it but I dumped it to file thus:</p>

<pre><code>kafka-console-consumer --zookeeper localhost:2181 --topic mySchemaTopic --from-beginning &gt; ~/schema.avsc
</code></pre>

<p>Here&rsquo;s a snippet of what it looks like:</p>

<pre><code>{
  &quot;type&quot; : &quot;record&quot;,
  &quot;name&quot; : &quot;MOVIE&quot;,
  &quot;namespace&quot; : &quot;ORCL.MOVIEDEMO&quot;,
  &quot;fields&quot; : [ {
    &quot;name&quot; : &quot;table&quot;,
    &quot;type&quot; : &quot;string&quot;
  }, {
    &quot;name&quot; : &quot;op_type&quot;,
    &quot;type&quot; : &quot;string&quot;
  }, {
[...]
</code></pre>

<p>Logstash can use the Avro <strong>codec</strong> to deserialise the data it&rsquo;s going to be pulling from Kafka. It isn&rsquo;t part of the standard distribution, so needs installing thus:</p>

<pre><code>/opt/logstash-2.2.0/bin/plugin install logstash-codec-avro
</code></pre>

<p>Now we can build our Logstash config file:</p>

<pre><code class="language-ruby"> input {
     kafka {
         zk_connect =&gt; 'bigdatalite:2181'
         topic_id =&gt; 'oggtopic'
         codec =&gt;
             avro {
                 schema_uri =&gt; &quot;/home/oracle/schema.avsc&quot;
             }
         # These next two options will force logstash to pull
         # the entire contents of the topic.
         reset_beginning =&gt; 'true'
         auto_offset_reset =&gt; 'smallest'
     }
 }

 output {
     stdout {
         codec =&gt; rubydebug
     }
 }
</code></pre>

<p>Note the syntax for referencing the Avro codec - if you follow the syntax in the docs it will fail with the error <code>undefined method `decode' for [&quot;avro&quot;</code>. Thanks to <a href="http://stackoverflow.com/a/33211940/350613">this Stackoverflow post</a> for help on fixing that problem.</p>

<p>Because we&rsquo;ve told Logstash to use the <strong>stdout</strong> output plugin we can see everything that it&rsquo;s reading from Kafka, and the <strong>rubydebug</strong> codec ensures that field names etc are nicely formatted. You can see from this the point of the Avro schema - it supports the idea of records deletions, as in this one:</p>

<pre><code>[oracle@bigdatalite logstash-2.2.0]$ /opt/logstash-2.2.0/bin/logstash -f ~/logstash-kafka-stdout.conf
Settings: Default pipeline workers: 4
Logstash startup completed
{
           &quot;table&quot; =&gt; &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
         &quot;op_type&quot; =&gt; &quot;D&quot;,
           &quot;op_ts&quot; =&gt; &quot;2016-03-16 22:14:47.000000&quot;,
      &quot;current_ts&quot; =&gt; &quot;2016-03-16T22:26:29.515000&quot;,
             &quot;pos&quot; =&gt; &quot;00000000010000002172&quot;,
    &quot;primary_keys&quot; =&gt; [
        [0] &quot;MOVIE_ID&quot;
    ],
          &quot;tokens&quot; =&gt; {},
          &quot;before&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;1&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;Foo&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
           &quot;after&quot; =&gt; nil,
        &quot;@version&quot; =&gt; &quot;1&quot;,
      &quot;@timestamp&quot; =&gt; &quot;2016-03-16T22:53:48.675Z&quot;
}
</code></pre>

<p>as well as inserts and updates:</p>

<pre><code>{
           &quot;table&quot; =&gt; &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
         &quot;op_type&quot; =&gt; &quot;I&quot;,
           &quot;op_ts&quot; =&gt; &quot;2016-03-16 22:32:21.000000&quot;,
      &quot;current_ts&quot; =&gt; &quot;2016-03-16T22:32:22.941000&quot;,
             &quot;pos&quot; =&gt; &quot;00000000010000003090&quot;,
    &quot;primary_keys&quot; =&gt; [
        [0] &quot;MOVIE_ID&quot;
    ],
          &quot;tokens&quot; =&gt; {},
          &quot;before&quot; =&gt; nil,
           &quot;after&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;4242&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;never gonna&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
        &quot;@version&quot; =&gt; &quot;1&quot;,
      &quot;@timestamp&quot; =&gt; &quot;2016-03-16T23:08:58.804Z&quot;
}
{
           &quot;table&quot; =&gt; &quot;ORCL.MOVIEDEMO.MOVIE&quot;,
         &quot;op_type&quot; =&gt; &quot;U&quot;,
           &quot;op_ts&quot; =&gt; &quot;2016-03-16 23:09:58.000000&quot;,
      &quot;current_ts&quot; =&gt; &quot;2016-03-16T23:10:01.023000&quot;,
             &quot;pos&quot; =&gt; &quot;00000000010000003700&quot;,
    &quot;primary_keys&quot; =&gt; [
        [0] &quot;MOVIE_ID&quot;
    ],
          &quot;tokens&quot; =&gt; {},
          &quot;before&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;4242&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;never gonna&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
           &quot;after&quot; =&gt; {
                      &quot;MOVIE_ID&quot; =&gt; &quot;4242&quot;,
            &quot;MOVIE_ID_isMissing&quot; =&gt; false,
                         &quot;TITLE&quot; =&gt; &quot;Foobar&quot;,
               &quot;TITLE_isMissing&quot; =&gt; false,
                          &quot;YEAR&quot; =&gt; &quot;2014&quot;,
                &quot;YEAR_isMissing&quot; =&gt; false,
                        &quot;BUDGET&quot; =&gt; &quot;500000&quot;,
              &quot;BUDGET_isMissing&quot; =&gt; false,
                         &quot;GROSS&quot; =&gt; &quot;20000000&quot;,
               &quot;GROSS_isMissing&quot; =&gt; false,
                  &quot;PLOT_SUMMARY&quot; =&gt; &quot;give you up&quot;,
        &quot;PLOT_SUMMARY_isMissing&quot; =&gt; false
    },
        &quot;@version&quot; =&gt; &quot;1&quot;,
      &quot;@timestamp&quot; =&gt; &quot;2016-03-16T23:10:11.043Z&quot;
}

</code></pre>

<p>If you want to get this into Elasticsearch you can send it there from Logstash, just by adding</p>

<pre><code> elasticsearch { hosts =&gt; &quot;localhost&quot;}
</code></pre>

<p>to the <code>output</code> stanza of the logstash configuration file. I hit the error</p>

<pre><code>SSLConnectionSocketFactory not found [...]
</code></pre>

<p>when I ran Logstash with Elasticsearch output option, to which a quick Google produced the answer; run <code>unset CLASSPATH</code> first.</p>

<p>With the data in Elasticsearch it&rsquo;s a matter of moments to get set up in Kibana and to start poking around it:</p>

<p><img src="/content/images/2016/03/2016-03-17_21-49-15.png" alt="" /></p>

<hr />

<p>So what&rsquo;s the point of all this? Well, I mentioned it partly above - jigsaws. It&rsquo;s fun seeing what fits together with what 8-) But more usefully, Kafka has a vital role to play in <a href="http://www.rittmanmead.com/2015/10/forays-into-kafka-enabling-flexible-data-pipelines/">flexible data pipelines</a>, and Logstash is just an easy example of one of the many consumers that can take advantage of data persisted in the buffer that Kafka provides. Logstash itself gives a bunch of integration permutations, if the desired target itself doesn&rsquo;t have a direct Kafka consumer (which something like Elasticsearch may have, with the advent of <a href="http://docs.confluent.io/2.0.0/connect/">Kafka Connect</a>).</p>

<p>Pulling the GoldenGate data into Elasticsearch as seen above is cool (c.f. jigsaws, or maybe Lego is a better analogy), and for poking around the Kafka messages and deserialising the Avro messages it&rsquo;s perfect, but given the CDC nature of it having update and delete transactions too it could be that <a href="https://www.elastic.co/products/hadoop">Elasticsearch-Hadoop</a> is a better route if you want a consistent point-in-time view of your data. Done that way you&rsquo;d have <a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/current/hive.html#_writing_data_to_elasticsearch_2">Hive pushing a copy of the data to Elasticsearch</a> thus:</p>

<pre><code>OGG -- [Kafka] --&gt; HDFS/Hive --&gt; Elasticsearch
</code></pre>

</article>

		</main>
		
				<div class="hide-print sans-serif f6 f5-l mt5 ph3 pb6 center nested-copy-line-height lh-copy nested-links mw-100 measure-wide">
		<div class="about-the-author">
		
			
			
				
					<hr />

<p><img src="/images/2018/05/ksldn18-01.jpg" alt="Robin Moffatt" /></p>

<p>Robin Moffatt is a Developer Advocate at Confluent, and Oracle Groundbreaker Ambassador. He also likes writing about himself in the third person, eating good breakfasts, and drinking good beer.</p>

				
			
		
		</div>
		
	</div>

		
		
		
		<footer class="hide-print sans-serif f6 fw1 bg-black near-white bottom-0 w-100 pa3" role="contentinfo">
			<p class="w-50 fr tr">
			<a class="no-underline near-white" href="https://github.com/xaprb/story"><img class="dib" title="Made with Hugo and Story" alt="Story logo" src="https://rmoff.github.io/img/story-logo-white.svg" style="width: 1.5rem; height: 1.5rem" /></a>
			</p>
			<p class="w-50 near-white">
				&copy; 2019 Robin Moffatt
			</p>
		</footer>
		
	
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-75492960-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	</body>
</html>
