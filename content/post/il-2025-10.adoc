---
draft: false
title: 'Interesting links - October 2025'
date: "2025-10-30T16:28:23Z"
image: "/images/2025/10/"
thumbnail: "/images/2025/10/"
credit: "https://bsky.app/profile/rmoff.net"
categories:
- Interesting Links
---

What with Current NOLA 2025 happening this week, and some _very_ last minute preparations for the demo at the keynote on day 2, this month's links round up is pushing it right up to the wire :)
The demo was pretty cool, and finally I have a good example of how this AI stuff actually fits into a workflow ;)
I'll write it up into a blog post (or two, probably)—stay tuned!

<!--more-->

Some self-promotion to begin with:

* This month a couple of colleagues and I launched https://flink-watermarks.wtf/[Flink Watermarks…WTF].
It's an interactive explainer about watermarks in Apache Flink.
Try it out and let me know what you think.

** Oh, and I even designed some stickers for it!
+
{{< video src="/images/2025/10/flink-watermarks.wtf" autoplay="true" muted="true" loop="true" controls="false" >}}
* I gave a talk about link:/talk/blog-writing-for-developers/[Blog Writing for Developers] - check out the link for slides and audio recording
* I was a guest on the Confluent Developer podcast - 🎥 https://www.youtube.com/watch?v=U0t5cCl9BWM[video here], 🎧 https://confluent.buzzsprout.com/186154/episodes/18059785-how-kafka-expert-robin-moffat-tackles-open-source-problems-ep-6[audio here]

With that, on with the interesting links!

_Not got time for all this? I've marked 🔥 for my top reads of the month_ :)


== Data Engineering and Architecture

* An updated version of a16z's 2020 post looking at https://a16z.com/emerging-architectures-for-modern-data-infrastructure/[Emerging Architectures for Modern Data Infrastructure].
* A summary from ByteByteGo on https://blog.bytebytego.com/p/how-pinterest-transfers-hundreds[how Pinterest use CDC].
* My Confluent colleague Alex Stuart wrote a good post about https://www.confluent.io/blog/data-lake-governance-tableflow/[Building a Better-Governed Data Lake Architecture].
* An interesting architecture idea from Ananth Packkildurai: https://www.dataengineeringweekly.com/p/revisiting-medallion-architecture-760[Data Vault in Silver, Dimensional Modeling in Gold].
* Where should data contracts go? Mark Freeman and Chad Sanderson https://dataproducts.substack.com/p/your-data-contracts-are-in-the-wrong[tell us].
* https://debezium.io/blog/2025/10/27/debezium-3-4-alpha1-released/[Debezium 3.4.0.Alpha1] has been released, which includes support for Postgres 18, OpenLineage output from Debezium Server, improvements to the Oracle LogMiner support, and more.
* It can't really be a month of interesting links without at least one from Jack Vanlightly, and this month we have two :)
The first is this well-reasoned argument as to why he https://jack-vanlightly.com/blog/2025/10/15/why-im-not-a-fan-of-zero-copy-apache-kafka-apache-iceberg[is not a fan of zero-copy for getting data from Kafka to Iceberg].
* What's the best way to add a new table in Debezium? Fiore Mario Vitale https://debezium.io/blog/2025/10/06/add-new-table-to-capture-list/[explains it here, including things to watch out for].
* Getting everyone (in the small world that is data engineering) all excited, Fivetran and dbt merged recently. Michael Driscoll has https://www.linkedin.com/posts/medriscoll_its-official-fivetran-and-dbt-have-coalesced-activity-7383593000905588736-jEC7/[a measured analysis of it] over on LinkedIn.
* Taking a broader look at what's become of the Modern Data Stack is https://moderndata101.substack.com/p/the-modern-data-stacks-final-act[this excellent article] from Travis Thompson and Animesh Kumar.
Insightful and detailed analysis with plenty of evidence to back up their hypotheses.
* I enjoyed reading this one, as my assumption about partitioning is exactly what Kirill Bobrov says here is https://luminousmen.com/post/how-not-to-partition-data-in-s3-and-what-to-do-instead/[not the way to do it] (and explains an alternative approach instead).Kirill Bobrov
* Petrica Leuca has an interesting post about https://medium.com/@petrica.leuca/d4ec74f76c55?sk=1a91e2a84bbddea6db54311129d3347b[time travel and versioning in DuckLake].
I'm even more of a fan because it starts from the point of investigating SCD type 2—what's not to like!
* Otter/CloudKitchens found both Stackdriver and OpenSearch too expensive for their logging needs—so https://techblog.cloudkitchens.com/p/our-journey-to-affordable-logging[they wrote their own] (in Rust, of course). They claim some impressive numbers—"750+ TiB of logs at 4.4x lower cost than self-hosted OpenSearch[…]50x cheaper than managed alternatives".
* Fresha have burst onto the data engineering blogging scene in recent months, sharing all sorts of excellent details about their platforms.
This post from Emiliano Mancuso explains https://medium.com/fresha-data-engineering/from-json-to-avro-in-the-cdc-pipeline-ff24ac9c9abc[why they moved from JSON to Avro] in their CDC pipelines to Snowflake.
* A decent https://www.onehouse.ai/blog/kafka-connect-vs-flink-vs-spark-choosing-the-right-ingestion-framework[comparison of the open-source data ingestion frameworks] (Flink/Kafka Connect/Spark) from Shiyan Xu at Onehouse.
If you notice a recurring theme of Spark cost and performance optimisation then I'm sure that not because Onehouse have their own tool to fix that ;)

== Kafka and Event Streaming

* Updated recently, Hans-Peter Grahsl and Gunnar Morling's https://a-great-day-out-with.github.io/kafka/index.html[A Great Day Out With... Apache Kafka] is a useful map of the tools and ecosystem.
* Vu Trinh does https://blog.dataengineerthings.org/is-your-data-valid-why-bufstream-guarantees-what-kafka-cant-ed84a1fcfcc9[a deep-dive on how the Kafka-compatible Bufstream handles data validation], comparing it to the Kafka + Schema Registry approach
* https://dev.to/ijuren/good-things-compression-take-time-1aed[Interesting analysis] from Ivan Juren on the `linger.ms` setting in Kafka and the throughput/latency/CPU trade-off.
* Federico Valeri has published a very well-written https://developers.redhat.com/articles/2025/09/17/deep-dive-apache-kafkas-kraft-protocol#[deep dive intoKafka's KRaft protocol].
* A nice https://github.com/dustin10/kaftui[TUI for Kafka] from Dustin Dobervich.
* The Queues feature for Kafka was added recently - https://github.com/ifnesi/queues-for-kafka[this demo from Italo Nesi] is a neat way to explore it.
* Klaviyo's Chinmay Sawaji has written a good post explaining how they https://klaviyo.tech/building-a-resilient-event-publisher-with-dual-failure-capture-518749cb5600[build their Kafka producers to be resilient to failures].
* In a fantastic example of both "just because I can" _and_ "I'm going to explain this thing using a cool example", Leandro Proença shows how to https://leandronsp.com/articles/you-dont-need-kafka-building-a-message-queue-with-only-two-unix-signals[rebuild Kafka using UNIX signals].
* In a somewhat more serious approach (I think?) Stanislav Kozlovski makes the case for https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks[using Postgres instead of Kafka in many situations].
Oliver Russell wrote about how is team actually do use https://leontrolski.github.io/postgres-as-queue.html[Postgres as a queue].
* Backfilling data in Kafka is definitely a "day 2" type problem, but a real one—and https://nejckorasa.github.io/posts/kafka-backfill/[Nejc Korasa has a nice write-up] of some of the patterns to consider.
* A https://github.com/j3-signalroom/kafka_cluster-topic-key_distribution_analyzer-tool[tool] from Jeffrey Jonathan Jennings to https://thej3.com/you-cant-optimize-what-you-can-t-measure-4db0cbf99b9b[analyse key distribution] and help avoid hot partitions.
* Probably the biggest discussion in the Apache Kafka community at the moment is the direction of the project with regards to "Diskless" (or "Direct-to-S3").
Here's a round-up of some of the key reading:
** Summary from https://cwiki.apache.org/confluence/display/KAFKA/The+Path+Forward+for+Saving+Cross-AZ+Replication+Costs+KIPs[Luke Chen] of the different proposals, and more recently analysis and commentary from https://jack-vanlightly.com/blog/2025/10/22/a-fork-in-the-road-deciding-kafkas-diskless-future[Jack Vanlightly].
** Discussion of the KIP-1150 proposal on the https://lists.apache.org/thread/ljxc495nf39myp28pmf77sm2xydwjm6d[Apache Kafka mailing list]
** More analysis and commentary from Fresha's https://medium.com/fresha-data-engineering/the-good-the-bad-and-the-automq-5aa7a8748e71[Anton Borisov].

== Stream Processing

* Excellent https://duckdb.org/2025/10/13/duckdb-streaming-patterns[article] (and https://github.com/guillesd/duckdb-streaming-patterns/tree/main[accompanying code repo]) from Guillermo Sanchez showing how low-latency analytics on data from Kafka can be done in DuckDB.
Adding this to my list to try out and write about myself, definitely :)
* In a similar vein, Yuxia Luo has published https://github.com/luoyuxia/duckdb-extension-fluss[a DuckDB extension to directly query Apache Fluss].
* Very cool blog post from the team at Grab on https://engineering.grab.com/ml-predictive-autoscaling-for-flink[using machine learning to predict workloads and scale Flink automagically].
* Milind Srivastava and colleagues at CMU have published a library of https://github.com/ProjectASAP/FlinkSketch[sketching algorithms] for Flink's DataStream API.
* Tools to use Flink from https://github.com/exness/go-flink-sql[Go] and https://github.com/devstress/FlinkDotnet[.NET].
* 🔥 Yennick Trevels has published both a https://kafkastreamsfieldguide.com/articles/kafka-streams-monitoring[Kafka Streams monitoring guide] as well as an excellent https://kafkastreamsfieldguide.com/articles/kafka-streams-grafana-dashboard[Grafana dashboard for Kafka Streams].
* Flink's Hadoop-rooted support for S3 has caused many travails for lots of people, https://www.decodable.co/blog/troubleshooting-flink-sql-s3-problems[including me]—and the community has recognised this with https://lists.apache.org/thread/2bllhqlbv0pz6t95tsjbszpm9bp9911c[a discussion beginning] about creating native support for S3 within Flink.
* Hands-on example from Gal Krispel at Riskified on https://medium.com/riskified-technology/overcoming-flinksql-limitations-with-a-hybrid-api-approach-9bbe6b569431[how they use Flink's DataStream API to validate and pre-process data to make their Flink SQL pipelines more resilient].
* Netflix's Adrian Taruc and James Dalton describe https://netflixtechblog.com/how-and-why-netflix-built-a-real-time-distributed-graph-part-1-ingesting-and-processing-data-80113e124acc[how they've used Kafka, Flink, and Iceberg to build a real-time distributed graph].
There's some good detail in there about the processing that Flink does, and their experiences in scaling it.
* A https://www.streamingdata.tech/p/flink-forward-2025[report from Flink Forward 2025] by Yaroslav Tkachenko.
* Reddit's Vignesh Raja and Jerry Chu write about their experience with Flink's tumbling window joins and https://www.reddit.com/r/RedditEng/comments/1o0lscn/evolving_signalsjoiner_with_custom_joins_in/[their own custom join implementation].

== Open Table Formats (OTF), Catalogs, etc.

* Shuiqiang Chen describes https://www.alibabacloud.com/blog/building-a-unified-lakehouse-for-large-scale-recommendation-systems-with-apache-paimon-at-tiktok_602568[how TikTok uses Apache Paimon in their recommendation systems].
* As well as writing from Kafka to Iceberg, Confluent's TableFlow now supports https://www.confluent.io/blog/tableflow-delta-lake-unity-catalog-azure/[writing to Delta Lake, upserts, and dead-letter queues].
* Iceberg catalog https://polaris.apache.org/[Apache Polaris] has released v1.2, and Alex Merced has written https://www.dremio.com/blog/whats-new-in-apache-polaris-1-2-0-fine-grained-access-event-persistence-and-better-federation/[an article about what's new].
Meanwhile, https://github.com/apache/gravitino/releases/tag/v1.0.0[Apache Gravitino] (with bigger ambitions beyond just an Iceberg catalog) has released v1.0.
* Dipankar Mazumdar has a good article comparing https://dipankar-tnt.medium.com/apache-parquet-vs-newer-file-formats-btrblocks-fastlanes-lance-vortex-cdf02130182c[Apache Parquet with newer file formats such as Lance and Vortex].
If new formats are your thing, a recent SIGMOD paper announced the open-source https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf[F3 (Future-proof File Format)].
Also doing the rounds this month was news of https://github.com/indextables/indextables_spark/[IndexTables] describes itself as "an experimental open-table format for Apache Spark that enables fast retrieval and full-text search across large-scale data", whilst https://github.com/microsoft/amudai[Project Amudai] is an "advanced columnar storage format […designed to] address the limitations of existing data lake formats, such as Apache Parquet".
* I https://speakerdeck.com/rmoff/analysing-the-panama-papers-with-oracle-big-data-spatial-and-graph[do like a property graph], and am interested to look more into https://graphar.apache.org/[Apache GraphAr (incubating)] which Sem Sinchenko describes https://semyonsinchenko.github.io/ssinchenko/post/dreams-about-graph-in-lakehouse/#headline-11[in this article] as a standard for Property Graph storage.
In other graph news, DuckDB has a https://duckdb.org/community_extensions/extensions/duckpgq[graph community extension] that Daniël ten Wolde https://duckdb.org/2025/10/22/duckdb-graph-queries-duckpgq#property-graphs-in-duckdb[shows in action here].
* Jack's back!
With a hat-trick of entries in this month's post, here he's looking at https://jack-vanlightly.com/blog/2025/10/8/beyond-indexes-how-open-table-formats-optimize-query-performance[How Open Table Formats Optimize Query Performance].
* Fresh'a Anton Borisov is back again with https://medium.com/fresha-data-engineering/iceberg-cdc-stream-a-little-dream-of-me-a7c9f9e6e11d[a look at the proposal for the next version of the Iceberg spec] and how it could improve things when working with CDC data.
* Vincent Daniel at Expedia writes about https://medium.com/expedia-group-tech/why-you-should-prefer-merge-into-over-insert-overwrite-in-apache-iceberg-b6b130cc27d2[Why You Should Prefer `MERGE INTO` Over `INSERT OVERWRITE`] in Iceberg.
* Kinda like benchmarks, feature comparisons published by vendors are inheritently biased—whether conciously or not.
Kyle Weller at Onehouse—who contribute to the Apache Hudi format—has published an updated https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison[feature comparison of Iceberg, Hudi, and Delta Lake].
You can guess which one comes out on top ;)
https://imgflip.com/i/aaq1pi[Snark aside], it's still a useful article if only to look at the positioning and strengths of Hudi.
* Videos from the recent https://www.youtube.com/playlist?list=PL3IALGSANhzXdkQfSBRaXoHYkOCWd2aUR[Greater Seattle] and https://www.youtube.com/playlist?list=PL3IALGSANhzWxlZpyGgwZiRYjhIStmBdq[San Francisco] Iceberg meetups

== AI

_I warned you link:/2025/09/30/interesting-links-september-2025/#_ai[last month]…this AI stuff is here to stay, and it'd be short-sighted to think otherwise._
_As I read and learn more about it, I'm going to share interesting links (the clue is in the blog post title) that I find—whilst trying to avoid the breathless hype and slop._

* I wrote a post trying to get my head around _what_ we mean by link:/2025/10/06/stumbling-into-ai-part-5agents/[Agents].
* https://basicmemory.com/[Basic Memory] is a very cool MCP server that integrates with your AI tool and acts as a memory of your conversations, storing the information locally in Markdown.
It integrates very neatly with Obsidian.
I'm a big fan.
* Confluent announced a bunch of neat stuff at Current this week including a https://www.confluent.io/blog/introducing-real-time-context-engine-ai/[real time context engine] and https://www.confluent.io/blog/2025-q4-streaming-agents-update/[streaming agents].
Product blog posts are m'kay I guess but I always like to see the hands-on detail, and so I enjoyed reading my colleague Yash Anand's example of https://medium.com/confluent/building-streaming-ai-agents-with-flink-sql-on-confluent-cloud-e3bb9fe3337a[building with streaming agents].
* Very cool talk (https://www.youtube.com/watch?v=jp-fBw07r7c[video] / https://dpe.org/wp-content/uploads/2024/06/Adam-Huda-and-Ty-Smith-Uber-AI.pptx.pdf[slides]) from Ty Smith and Adam Huda with real-world examples of how Uber's developers are using AI and what benefits they're seeing.
* https://flink.apache.org/2025/10/15/apache-flink-agents-0.1.0-release-announcement/[Apache Flink Agents] is a sub-project of Apache Flink, and they just had their first release.
* https://www.anthropic.com/news/skills[Claude Skills] are the https://simonwillison.net/2025/Oct/16/claude-skills/#skills-compared-to-mcp[latest hawtness] (at least until the next thing comes along tomorrow), and Gordon Murray has published a https://github.com/gordonmurray/data-engineering-skills[set of them] with support for technologies including Flink, Fluss, and Iceberg.
* As well as changing how we get things done, AI is probably going to change how we build platforms too.
Ananth Packkildurai has a good analysis[https://www.dataengineeringweekly.com/p/what-supporting-our-ai-overlords] of two papers looking at how Agents use data and how systems might be better designed for that, and
Ciro Greco looks at how Agents involved in carrying out data engineering tasks might https://gradientflow.substack.com/p/the-convergence-of-data-ai-and-agents[drive platform requirements].

== General Data Stuff

* Datadog process over _100 *trillion* events per day_, and wrote their own event store called Husky to handle it.
They've written previously about how it handles https://www.datadoghq.com/blog/engineering/husky-deep-dive/[exactly-once ingestion] and https://www.datadoghq.com/blog/engineering/husky-storage-compaction/[compaction], and in their most recent post Sami Tabet explains how they built its https://www.datadoghq.com/blog/engineering/husky-query-architecture/[interactive querying capabilities].
* A nice concise list from Jordan Goodman of https://datamethods.substack.com/p/sql-anti-patterns-you-should-avoid[SQL Anti-Patterns You Should Avoid].
* What happens when you run DuckDB with a 10TB dataset on a 64 core/512GB machine?
Mimoune Djouallah https://datamonkeysite.com/2025/10/19/running-duckdb-at-10-tb-scale/[found out].
* https://github.com/Basekick-Labs/arc[Arc] is a time-series database built on DuckDB, Parquet, and Arrow, and claims ingestion rates of 2.4M records/sec.
* Alexey Makhotkin has some excellent content on his blog, including this one looking at the https://kb.databasedesignbook.com/posts/systematic-design-of-join-queries/[systematic design of multi-join `GROUP BY` queries].
* Having recently helped build https://flink-watermarks.wtf/ I now pay much more attention to examples of _scrollytelling_—and this one from Nanda Syahrasyad showing how to https://www.nan.fyi/database[Build Your Own Database] is really good!
* Postgres 18 was released recently, and Ben Dicken did some https://planetscale.com/blog/benchmarking-postgres-17-vs-18[benchmarking comparing it to Postgres 17]
* https://practicaldatamodeling.substack.com/p/how-to-sell-data-modeling[Practical advice from Joe Reis on data modeling]—specifically, how to get buy-in from your company to actually do it properly.
* Described as an "open-source immutable SQL database with comprehensive time-travel", XTDB https://xtdb.com/blog/launching-xtdb-v2[released v2] earlier this year.
* Robert Yokota writes about the Robustness Principle (a.k.a. Postel's Law) in the context of https://yokota.blog/2025/10/07/json-schema-compatibility-and-the-robustness-principle/[JSON Schema compatability].

== Data in Action

* OpenAI's Bohan Zhang spoke at PGConf this year about their https://www.youtube.com/watch?v=Ni1SGhNu-Q4[use of Postgres and experience scaling it].
For more details of OpenAI's data platforms check out this blog post summarising https://blog.bytebytego.com/p/how-openai-uses-kubernetes-and-apache[how they deploy Kafka and Flink on Kubernetes].
* Aakash Pradeep and his colleagues at Twilio built Odin, which is a https://aws.amazon.com/blogs/big-data/how-twilio-built-a-multi-engine-query-platform-using-amazon-athena-and-open-source-presto/[multi-engine query platform enabling them to offer Amazon Athena alongside the existing Presto].
* Details of how Chinese ride-sharing company DiDi's https://medium.com/starrocks-engineering/how-didi-transformed-real-time-risk-engineering-with-starrocks-33979acc6cb9[evaluation of StarRocks against ClickHouse].
Also from StarRocks is a look at VBill's https://medium.com/starrocks-engineering/empowering-instant-insights-how-vbill-payment-powers-real-time-analytics-at-tens-of-billions-scale-c714a5a740aa[migration of a real-time data pipeline] from a Kudu/HBase/Hive architecture to StarRocks and some of the optimisations implemented.
* It's more about _video_ streams than _event_ streams, but this https://netflixtechblog.com/behind-the-streams-live-at-netflix-part-1-d23f917c2f40[three] https://netflixtechblog.com/building-a-reliable-cloud-live-streaming-pipeline-for-netflix-8627c608c967[part] https://netflixtechblog.com/behind-the-streams-real-time-recommendations-for-live-events-e027cb313f8f[series] from Netflix is a fascinating behind-the-scenes explainer of how things work.
* A two-part series from Kakao describing their https://tech.kakao.com/posts/776[implementation] and https://tech.kakao.com/posts/777[troubleshooting] of a CDC pipeline with Kafka Connect from Postgres to Elasticsearch.
_It's in Korean but if you open it in Chrome etc the in-browser translation tool will work wonders :)_
* Ankit Sultana and his colleagues at Uber https://www.uber.com/blog/rebuilding-ubers-apache-pinot-query-architecture/[write about their migration] from a Presto-based proxy in front of Pinot toward a Pinot-native architecture including Pinot's Multi-Stage Engine Lite Mode to serve real-time analytics workloads.

== And finally…

_Nothing to do with data, but stuff that I've found interesting or has made me smile._
*Turns out there was quite a lot that amused me this month 😁.*

* https://andyjakubowski.github.io/statechart-watch/[Citizen Watch]
* https://blog.peterzhu.ca/open-source-is-the-most-fragile-and-resilient-ecosystem/[Open Source is the Most Fragile and Most Resilient Ecosystem - Peter Zhu]
* https://blog.pixelmelt.dev/kindle-web-drm/[How I Reversed Amazon's Kindle Web Obfuscation Because Their App Sucked]
* https://bradstulberg.substack.com/p/a-simple-formula-for-responding-not[A Simple Formula for Responding not Reacting]
* https://databased.pedramnavid.com/p/reflections-on-2-years-running-developer[Reflections on 2 Years Running Developer Relations]
* https://dmkskd.github.io/sql-shader/[SQL Shader]
* So You Want to Be Promoted https://randsinrepose.com/archives/so-you-want-to-be-promoted-pt-1/[Pt. 1] & https://randsinrepose.com/archives/so-you-want-to-be-promoted-pt-2/[Pt. 2]
* https://scribe.rip/[Scribe]
* https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/[Stop Avoiding Politics – Terrible Software]
* https://theoatmeal.com/comics/ai_art[A cartoonist's review of AI art - The Oatmeal]
* https://time.is/GMT[Greenwich Mean Time: 17:04]
* https://vkoskiv.com/first-linux-patch/[My First Contribution to Linux]
* https://www.youtube.com/watch?v=o4TdHrMi6do[A laser pointer at 2 billion fps makes the speed of light look... kinda weird - YouTube]
* https://www.youtube.com/watch?app=desktop&v=cUbIkNUFs-4[The Original Square Hole Girl Video + The Redemption - YouTube]
* https://www.youtube.com/watch?v=w3ma9iYx4rg[1982: FRED DIBNAH shows HOW to erect a CHIMNEY SCAFFOLD at 200 feet! \| Fred \| 1980s \| BBC Archive - YouTube]

---

TIP: If you like these kind of links you might like to read about https://rmoff.net/2024/05/22/how-i-try-to-keep-up-with-the-data-tech-world-a-list-of-data-blogs/[How I Try To Keep Up With The Data Tech World (A List of Data Blogs)]


== scratch
* https://aws.amazon.com/blogs/big-data/unlock-real-time-data-insights-with-schema-evolution-using-amazon-msk-serverless-iceberg-and-aws-glue-streaming/[Unlock real-time data insights with schema evolution using Amazon MSK Serverless, Iceberg, and AWS Glue streaming \| AWS Big Data Blog]
* https://rasmusengelbrecht.substack.com/p/practical-guide-to-semantic-layers[Practical Guide to Semantic Layers: From Definition to Demo (Part 1)]
* https://www.ssp.sh/blog/agentic-data-modeling/[Data Modeling for the Agentic Era: Semantics, Speed, and Stewardship \| ssp.sh]
* https://spoud-io.medium.com/how-to-compare-two-kafka-topics-8a977adb9d2d[Medium]
* https://www.linkedin.com/posts/sap1ens_flinkforward-activity-7384143771803934720-iJaD/[VERA-X: Ververica's Flink Accelerator vs Iron Vector \| Yaroslav Tkachenko posted on the topic \| LinkedIn]
* https://medium.com/@avikm744/why-we-have-chosen-fluvio-over-apache-flink-c16ec9284b8b[Why We have Chosen Fluvio over Apache Flink? \| by Avik Mukherjee \| Oct, 2025 \| Medium]
* https://medium.com/google-cloud/dataflow-kafka-offset-deduplication-06770942c325[Introducing Kafka Offset Deduplication for Dataflow \| by Tom Stepp \| Google Cloud - Community \| Oct, 2025 \| Medium]
* https://medium.com/@yingjunwu/we-built-an-open-source-s3-tables-alternative-2b3c95ef4b3a[We Built an Open Source S3 Tables Alternative \| by Yingjun Wu \| Oct, 2025 \| Data Engineer Things]
* https://github.com/djouallah/duckrun[GitHub - djouallah/duckrun]
* https://www.infoq.com/presentations/agentic-ai/[Beyond the Hype: Architecting Systems with Agentic AI - InfoQ]
* https://clickhouse.com/blog/netflix-petabyte-scale-logging[How Netflix optimized its petabyte-scale logging system with ClickHouse]
* https://tech.scribd.com/blog/2025/building-scalable-data-warehouse-backup-system.html[Building a Scalable Data Lake Backup System with AWS \| Scribd Technology]



== Future?
* https://www.ssp.sh/brain/data-lake-file-formats/[Data Lake File Formats]
* https://www.linkedin.com/posts/anton-s-borisov_breaking-the-ice-with-starrocks-activity-7388980467749863424-bmT3[Breaking the Ice with StarRocks \| Anton Borisov]
* https://jyu.dev/blog/why-dev-null-is-an-acid-compliant-database/[Why /dev/null Is an ACID Compliant Database • Joey's HQ]
* https://www.reddit.com/r/dataengineering/comments/1o6sfce/realtime_data_analytics_at_scale_integrating/[Reddit - The heart of the internet]
* https://www.dataengineeringweekly.com/p/engineering-growth-the-data-layers[Engineering Growth: The Data Layers Powering Modern GTM]
