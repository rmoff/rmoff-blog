---
draft: false
title: 'Stumbling into AI: Part 5â€”Agents'
date: "2025-09-17T09:12:04Z"
image: "/images/2025/09/"
thumbnail: "/images/2025/09/"
credit: "https://bsky.app/profile/rmoff.net"
categories:
- AI
- Agents
- Stumbling into AI
---

:source-highlighter: rouge
:icons: font
:rouge-css: style
:rouge-style: monokai

_A link:/categories/stumbling-into-ai[short series] of notes for myself as I learn more about the AI ecosystem as of September 2025._
_The driver for all this is understanding more about Apache Flink's https://github.com/apache/flink-agents[*Flink Agents*] project, and Confluent's https://www.confluent.io/product/streaming-agents/[**Streaming Agents**]._

I started off link:/categories/stumbling-into-ai/[this series] somewhat randomly, looking at link:/2025/09/04/stumbling-into-ai-part-1mcp/[Model Context Protocol (MCP)].
It's pretty neat, but it's a helper technology to make things easier to use and provide a richer experience.
Next I tried to wrap my head around link:/2025/09/08/stumbling-into-ai-part-2models/[Models]â€”mostly LLMs, but also with an link:/2025/09/08/stumbling-into-ai-part-2models/#_addendum_there_are_models_and_then_there_are_models_a_k_a_not_all_models_are_llms[addendum] discussing other types of model too.
Along the lines of MCP, link:/2025/09/12/stumbling-into-ai-part-3rag/[Retrieval Augmented Generation (RAG)] is another helper technology that on its own doesn't do anything but combined with an LLM gives it added smarts.
I took a brief moment in link:/2025/09/16/stumbling-into-ai-part-4terminology-tidyup-and-a-little-rant/[part 4] to try and build a clearer understanding of the difference between _ML_ and _AI_.
So whilst RAG and MCP combined make for a bunch of nice capabilities beyond the LLM alone, what I'm really circling around here is what we can when we combine all these things: *Agents*!

<!--more-->

== Start with the obvious: What is an Agent?

Let's go with https://en.wikipedia.org/wiki/Software_agent[Wikipedia's definition]:

> In computer science, a software agent is a computer program that acts for a user or another program in a relationship of agency.

We can get more specialised if we look at Wikipedia's entry for an https://en.wikipedia.org/wiki/Intelligent_agent[Intelligent Agent]:

> In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge.

Citing Wikipedia is perhaps the laziest ever blog author's trick, but I offer no apologies ðŸ˜œ.
Behind all the noise and fuss, this is what we're talking about: a bit of software that's going to go and do something for you (or your company) _autonomously_.

== OK, so _Agentic_ AI?

`Agentic` comes from `Agent` plus `ic`, the latter meaning _of, relating to, or characterised by_.

So `Agentic AI` is simply AI that is _characterised by_ an Agent, or Agency.
Contrast that to AI that's you sat at the ChatGPT prompt asking it to draw pictures of a duck dressed as a clown.
Nothing Agentic about thatâ€”just a human-led and human-driven interaction.

"AI Agents" becomes a bit of a mouthful with the qualifier, so much of the current industry noise is simply around "Agents".
That said, "Agentic AI" sounds cool, so gets used as the marketing term in place of "AI" alone.

== Okay okayâ€¦but what is an [AI] Agent?

A straightforward software agent might do something like:

> Order more biscuits when there are only two left

The pseudo-code looks like this:

[source,basic]
----
10      BISCUITS == FN_CHECK_BISCUIT_LEVEL()
20      IF BISCUITS < 2 THEN CALL ORDER_MORE_BISCUITS
30      GOTO 10
----

We take this code, stick it on a server and leave it to run.
One happy agent, done.

An AI Agent would look more like this:

[source,basic]
----
10      BISCUITS == FN_CHECK_BISCUIT_LEVEL()
20      IF BISCUITS < 2 THEN
        REM (Here's the clever AI stuff ðŸ‘‡)
            Work out who is in the office next week
            Look up their biscuit preference for jammy dodgers vs hobnobs
            Look at what biscuits are in stock at the supplier
            Place a biscuit order
30      GOTO 10
----

Other examples of AI Agents include:

* *Travel booking*.
Perhaps you tell it when you want to go, the kind of vacation you like, and what your budget is; it then goes and finds where it nice at that time of year, figures out travel plans within your budget, and either proposes an itinerary or even books it for you.
Another variation would be you tell it *where*, and then it integrates with your calendar to figure out the _when_.
* *Coding agents*.
Everyone's favourite tool (when used right).
It can reason about code, it can write code, it can review PRs.

=== Multi-agent System (MAS)

Just as you can build computer systems as monoliths (everything done in one place) or microservices (multiple things, each responsible for a discrete operation or domain), you can also have one big agent trying to do everything (probably not such a good idea) or individual agents each good at their particular thing that are then hooked together into what's known as a Multi-agent System (MAS).
Sean Falconer's https://seanfalconer.medium.com/building-a-meal-planning-agent-with-apache-kafka-and-apache-flink-254bc5a8d7c5[family meal planning demo] is a good example of a MAS.
One agent plans the kids meals, one the adult's meals, another combines the two into a single plan, and so on.

=== Human in the Loop (HITL)

This is a term you'll come across referring to the fact that agents might be pretty good, but they're not infallible.
In the travel booking example above, do we _really_ trust the agent to book the best holiday for us?
Almost certainly we'd want, at a minimum, the option to sign-off on the booking before it goes ahead and sinks Â£10k on an all-inclusive trip to Bognor Regis.

Then again, we're probably happy enough for an agent to access our calendars without asking permission, and as to whether they need permission or not to create a meeting is up to us and how much we trust them.

Every time an Agent requires HITL, it reduces its autonomy and/or responsiveness to situations.
As well as simply using smarter models that make fewer mistakes, there are other things that an Agent can do to reduce the need for HITL such as using guardrails to define acceptable parameters.
For example, an Agent is allowed to book travel but only up to a defined threshold.
That way the user gets to trade off convenience (no HITL) with risk (unintended first class flight to Hawaii).

== Building an Agent

LangChain
LlamaIndex
LangGraph

=== Where does an Agent run?

=== Interacting with the outside worldâ€”Tools and MCP
=== Interacting with the outside worldâ€”RAG


== Memory

https://www.morling.dev/blog/this-ai-agent-should-have-been-sql-query/#_agents_require_memory
https://docs.google.com/document/d/1asVTObtzIye0I9ypAztaeeI_sr_Hx2TORE02uUuqH_c/edit?tab=t.0#heading=h.v6u4ntwfeghw

Short-term memory
Semantic long-term memory
Procedural long-term memory
how you define your agent in code
episodic long term memory
    run RAG on the short term memory


== Planning

== Reflection

== Testing

== A2A


== Further reading

* ðŸ“ƒ https://arxiv.org/pdf/2304.03442[Generative Agents: Interactive Simulacra of Human Behavior]
* ðŸŽ¥ Paul Iusztin - https://www.infoq.com/presentations/llm-data-code-model-prompt/[The Data Backbone of LLM Systems] - QCon London 2025
* ðŸ“– Antonio Gulli - https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/preview?tab=t.0#[Agentic Design Patterns]
* Gunnar Morling - https://www.morling.dev/blog/this-ai-agent-should-have-been-sql-query/[This AI Agent Should Have Been a SQL Query]
* Sean Falconer - https://seanfalconer.medium.com/?source=post_page---byline--507b1ec456a6---------------------------------------[Why Googleâ€™s Agent2Agent Protocol Needs Apache Kafka]
