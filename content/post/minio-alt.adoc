---
draft: false
title: 'Alternatives to MinIO for single-node local S3'
date: "2026-01-14T09:42:10Z"
image: "/images/2026/01/h_IMG_3845.jpeg"
thumbnail: "/images/2026/01/t_IMG_3807.jpeg"
credit: "https://bsky.app/profile/rmoff.net"
categories:
- S3
- MinIO
- Apache Iceberg
---

:source-highlighter: rouge
:icons: font
:rouge-css: style
:rouge-style: monokai

In late 2025 the company behind MinIO https://github.com/minio/object-browser/pull/3509[decided] https://github.com/minio/minio/issues/21647#issuecomment-3418675115[to] https://github.com/minio/minio/commit/27742d469462e1561c776f88ca7a1f26816d69e2[abandon] it to pursue other commercial interests.
As well as upsetting a bunch of folk, it also put the cat amongst the pigeons of many software demos that relied on MinIO to emulate S3 storage locally, not to mention build pipelines that used it for validating S3 compatibility.

In this blog post I'm going to look at some alternatives to MinIO.

<!--more-->

Whilst MinIO is a lot more than 'just' a glorified tool for emulating S3 when building demos, my focus here is going to be on what is the _simplest_ replacement.
In practice that means the following:

* *Must* have a Docker image.
    ** So many demos are shipped as Docker Compose, and no-one likes brewing their own Docker images unless _really_ necessary.
* *Must* provide S3 compatibility.
    ** The whole point of MinIO in these demos is to stand-in for writing to actual S3.
* *Must* be free to use, with a strong preference for Open Source (per https://opensource.org/osd[OSI definition]) licence e.g. Apache 2.0.
* Should be **simple** to use for a *single-node deployment*
* Should have a clear and active community and/or commercial backer.
    ** _Any fule can vibe-code some abandon-ware slop, or fork a project in a fit of enthusiasm‚Äîbut MinIO stood the test of time until now and we don't want to be repeating this exercise in six months' time._
* Bonus points for excellent developer experience (DX), smooth configuration, good docs, etc.

NOTE: I'm purely looking at the single-node local S3 experience.
Several of the tools discussed below have a wide range of features, S3 support being just one of them.
Others offer S3 alone and that's it.
For my purposes either is fine, so long as any additional features and support don't add to the complexity or weight of deployment.

What I'm *not* looking at is, for example, multi-node deployments, distributed storage, production support costs, GUI capabilities, and so on.
That is, this blog post is not aimed at folk who were using MinIO as self-managed S3 in production.
Feel free to leave a comment below though if you have useful things to add in this respect :)

TIP: All of the code in this project can be found in https://github.com/rmoff/minio-alternatives[this repo].

== MinIO baseline

My starting point for this is a very simple Docker Compose stack: DuckDB to read and write Iceberg data that's stored on S3, provided by MinIO to start with.

You can find the code https://github.com/rmoff/minio-alternatives/blob/main/minio/docker-compose.yml[here].

The Docker Compose is pretty straightforward:

1. DuckDB, obviously, along with Iceberg REST Catalog
2. MinIO (S3 local storage)
3. `mc`, which is a MinIO CLI and used to automagically create a bucket for the data.

image::/images/2026/01/minio01.excalidraw.png[]

When I insert data into DuckDB:

[source,sql]
----
INSERT INTO cat.test.products VALUES
    (1, 'Widget', 9.99),
    (2, 'Gadget', 19.99),
    (3, 'Doohickey', 14.99);
----

it ends up in Iceberg format on S3, here in MinIO:

[source,bash]
----
$ mc ls minio/warehouse/test/products/data/

[2026-01-12 14:35:55 UTC]   693B STANDARD 019bb2a2-8ad5-7159-968c-3693c3578902.parquet
[2026-01-12 14:35:55 UTC] 2.7KiB STANDARD 188ee032-8576-4f46-9834-1cac6d3080a3-m0.avro
[2026-01-12 14:35:55 UTC] 1.6KiB STANDARD snap-2633370813252912097-95ad4df0-3243-4cfb-a736-8f785aac100c.avro
----

In each of the samples I've built you can run the `test.sh` to verify it.

[source,bash]
----
‚ùØ ./test.sh

    ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë
    ‚ñí                                                      ‚ñí
    ‚ñì      ___                    ‚ñì‚ñì‚ñì‚ñì‚ñì                    ‚ñì
    ‚ñà  ___( o)>  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì  ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí           ‚ñà
    ‚ñà  \ <_. )   ‚îÇ  DUCKDB   ‚îÇ  ‚ñì‚ñëLocal S3 ‚ñë‚ñì  ‚ñí‚ñí‚ñí‚ñí        ‚ñà
    ‚ñà    ---     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚ñì‚ñì MinIO  ‚ñí‚ñí‚ñí             ‚ñà
    ‚ñì           ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì        ‚ñë‚ñë‚ñë                 ‚ñì
    ‚ñí  ‚âã‚âã‚âã‚âã‚âã‚âã‚âã  ‚îÉ  ICEBERG    ‚îÉ  ‚âã‚âã‚âã‚âã‚âã‚âã‚âã‚âã  Smoke test      ‚ñí
    ‚ñë  ‚âã‚âã‚âã‚âã‚âã‚âã‚âã  ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ  ‚âã‚âã‚âã‚âã‚âã‚âã‚âã‚âã                  ‚ñë
    ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë

1. Checking MinIO buckets (before)...
[2026-01-14 12:48:41 UTC]     0B warehouse/

2. Creating Iceberg table and inserting data...
[‚Ä¶]

3. Verifying data in DuckDB...
[‚Ä¶]

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  id   ‚îÇ   name    ‚îÇ     price     ‚îÇ
‚îÇ int32 ‚îÇ  varchar  ‚îÇ decimal(10,2) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ     1 ‚îÇ Widget    ‚îÇ          9.99 ‚îÇ
‚îÇ     2 ‚îÇ Gadget    ‚îÇ         19.99 ‚îÇ
‚îÇ     3 ‚îÇ Doohickey ‚îÇ         14.99 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

4. Checking MinIO bucket contents (after)...
[2026-01-14 12:49:07 UTC]   493B STANDARD data/019bbc8d-7d44-7b6b-af71-0ab99d3a0124.parquet
[2026-01-14 12:49:07 UTC] 2.7KiB STANDARD data/c37ab68c-8aaf-44a4-88e6-bc02a01daf5c-m0.avro
[2026-01-14 12:49:07 UTC] 1.6KiB STANDARD data/snap-1988745121468861337-95e77212-9571-423f-bb71-ce8f1b4282f0.avro
[2026-01-14 12:49:07 UTC] 1.0KiB STANDARD metadata/00000-8bf22118-d262-47a9-986c-721d2b99a846.metadata.json
[2026-01-14 12:49:07 UTC] 1.7KiB STANDARD metadata/00001-5cad6fc5-fe54-41bc-8131-4d6f900d20e7.metadata.json
----

== MinIO alternatives

Let's now explore the different alternatives to MinIO, and how easy they are to switch MinIO out for.

I've taken the above project and tried to implement it with as few changes to use the replacement for MinIO.
I've left the MinIO S3 client, `mc` in place since that's no big deal to replace if you want to rip out MinIO completely (s3cmd, `aws` CLI, etc etc).

=== https://github.com/gaul/s3proxy[S3Proxy]

üíæ https://github.com/rmoff/minio-alternatives/blob/main/s3proxy/docker-compose.yml[Example Docker Compose]

Version tested: `3.0.0`

* ‚úÖ https://hub.docker.com/r/andrewgaul/s3proxy/[Docker image] (5M+ pulls)
* ‚úÖ Licence: https://github.com/gaul/s3proxy/blob/master/LICENSE[Apache 2.0]
* ‚úÖ https://github.com/gaul/s3proxy?tab=readme-ov-file#limitations[S3 compatibility]

Ease of config: üëçüëç

Very easy to implement, and seems like a nice lightweight option.

NOTE: One thing I did notice was that one of the projects that S3Proxy uses, https://jclouds.apache.org/[jclouds], was moved to the Apache Attic (i.e. retired) in mid-2025‚Äîalthough probably nbd if you're only using local storage anyway?


=== https://github.com/rustfs/rustfs[RustFS]

üíæ https://github.com/rmoff/minio-alternatives/blob/main/rustfs/docker-compose.yml[Example Docker Compose]

Version tested: `1.0.0-alpha.79`

Ease of config: ‚úÖ‚úÖ

* ‚úÖ https://hub.docker.com/r/rustfs/rustfs[Docker image] (100k+ pulls)
* ‚úÖ Licence: https://docs.rustfs.com/developer/license.html[Apache 2.0]
* ‚úÖ https://docs.rustfs.com/features/s3-compatibility/[S3 compatibility]

NOTE: Be aware that there was recently a https://github.com/rustfs/rustfs/security/advisories/GHSA-h956-rh7x-ppgj[pretty bad security vuln] found in RustFS, which has put some people off from using it.
The website looks pretty smart but several links resolve to the same page, giving it that "fresh paint" smell of a new project :)
This might matter less for demos, if it's easy to switch out.
You'll also note that the project is currently only 'alpha' release.

image::/images/2026/01/rustfs.excalidraw.png[]

RustFS also includes a GUI:

image::/images/2026/01/rustfs-gui.png[]

=== https://github.com/seaweedfs/seaweedfs[SeaweedFS]

üíæ https://github.com/rmoff/minio-alternatives/blob/main/seaweedfs/docker-compose.yml[Example Docker Compose]

Version tested: `4.06`

* ‚úÖ https://hub.docker.com/r/chrislusf/seaweedfs[Docker image] (5M+ pulls)
* ‚úÖ Licence: https://github.com/seaweedfs/seaweedfs/blob/master/LICENSE[Apache 2.0]
* ‚úÖ https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API[S3 compatibility]

Ease of config: üëç

image::/images/2026/01/seaweedfs.excalidraw.png[]

https://github.com/seaweedfs/seaweedfs/wiki/Quick-Start-with-weed-mini[This quickstart] is useful for getting bare-minimum S3 functionality working.
(That said, I still just got Claude to do the implementation‚Ä¶).
Overall there's not too much to change here; a fairly straightforward switchout of Docker images, but the auth does need its own config file (which as with Garage, I inlined in the Docker Compose).

_Edit: Straight after posting this blog, the project replied to say they'll be removing this extra requirement, making it even easier to use! How cool is that :)_

{{< x user="SeaweedFS" id="2011545347685040449" >}}

SeaweedFS comes with its own basic UI which is handy:

image::/images/2026/01/seaweedfs-ui.png[]

The https://seaweedfs.com/[SeaweedFS website] is surprisingly sparse and at a glance you'd be forgiven for missing that it's an OSS project, since there's a "pricing" option and the title of the front page is "SeaweedFS Enterprise" (and no GitHub link that I could find!).
But an OSS project it is, and a long-established one: SeaweedFS has been around with S3 support since its https://github.com/seaweedfs/seaweedfs/releases/tag/0.91[0.91 release in 2018].
You can also learn more about SeaweedFS from these https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?slide=id.p#slide=id.p[slides], including a https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?slide=id.g3593a652b55_0_473#slide=id.g3593a652b55_0_473[comparison chart with MinIO].

=== https://github.com/scality/cloudserver[Zenko CloudServer]

üíæ https://github.com/rmoff/minio-alternatives/blob/main/cloudserver/docker-compose.yml[Example Docker Compose]

Version tested: `9.2.8`

* ‚úÖ https://github.com/scality/cloudserver/pkgs/container/cloudserver/606409638?tag=9.2.8[Docker image] (also outdated ones on https://hub.docker.com/r/zenko/cloudserver[Docker Hub] with 5M+ pulls)
* ‚úÖ Licence: https://github.com/scality/cloudserver/blob/development/9.2/LICENSE[Apache 2.0]
* ‚úÖ https://github.com/scality/cloudserver?tab=readme-ov-file#overview[S3 compatibility]

Ease of config: üëç

image::/images/2026/01/cloudserver.excalidraw.png[]

Formerly known as S3 Server, CloudServer is part of a toolset called Zenko, published by Scality.
It drops in to replace MinIO pretty easily, but I did find it slightly tricky at first to disentangle the set of names (cloudserver/zenko/scality) and what the actual software I needed to run was.
There's also a slightly odd feel that the docs link to an outdated Docker image.


=== https://git.deuxfleurs.fr/Deuxfleurs/garage[Garage]

üíæ https://github.com/rmoff/minio-alternatives/blob/main/garage/docker-compose.yml[Example Docker Compose]

Ease of config: üòµ

Version tested: `1.0.0`

* ‚úÖ https://hub.docker.com/r/dxflrs/garage[Docker image] (1M+ pulls)
* ‚úÖ Licence: https://git.deuxfleurs.fr/Deuxfleurs/garage/src/branch/main-v2/LICENSE[AGPL]
* ‚úÖ https://garagehq.deuxfleurs.fr/documentation/reference-manual/features/[S3 compatibility]


I had to get https://code.claude.com/docs/en/overview[a friend] to help me with this one.
As well as the `garage` container, I needed another to do the initial configuration, as well as a TOML config file which I've inlined in the Docker Compose to keep things concise.

image::/images/2026/01/garage.excalidraw.png[]

Could I have sat down and RTFM'd to figure it out myself? Yes.
Do I have better things to do with my time? Also, yes.

So, Garage _does_ work, but gosh‚Ä¶it is _not_ just a drop-in replacement in terms of code changes.
It requires different plumbing for initialisation, and it's not simple at that either.
A simple example: `The specified key ID is not a valid Garage key ID (starts with GK, followed by 12 hex-encoded bytes)`.
Excellent for production hygiene‚Ä¶overkill for local demos, and in fact somewhat of a hindrance TBH.

NOTE: Is this an entirely fair assessment?
If I were looking at it as a new piece of technology in its own right, completely not!
Many pieces of excellent technology, particularly those that can support running distributed, will have a steep learning curve for configuration.
However, my requirement here is a _simple_ drop-in replacement for MinIO‚Äîwhich Garage is not.


=== https://github.com/apache/ozone[Apache Ozone]

üíæ https://github.com/rmoff/minio-alternatives/blob/main/apache-ozone/docker-compose.yml[Example Docker Compose]

Version tested: `2.1.0`

* ‚úÖ https://hub.docker.com/r/apache/ozone[Docker images] (1M+ pulls)
* ‚úÖ Licence: https://github.com/apache/ozone/blob/master/LICENSE.txt[Apache 2.0]
* ‚úÖ https://ozone.apache.org/docs/2.1.0/interface/s3.html[S3 compatibility]

Ozone was spun out of Apache Hadoop (remember that?) https://apache.org/foundation/records/minutes/2020/board_minutes_2020_10_21.txt[in 2020], having been initially created as part of the HDFS project back in 2015.

Ease of config: üòµ

image::/images/2026/01/apacheozone.excalidraw.png[]

It does work as a replacement for MinIO, but it is not a lightweight alternative; neither I nor Claude could figure out how to deploy it with any fewer than **four** nodes.
It gives heavy Hadoop vibes, and I wouldn't be rushing to adopt it for my use case here.

=== https://docs.ceph.com/en/reef/radosgw/#object-gateway[Ceph Object Gateway]

I took one look at the https://docs.ceph.com/en/reef/cephadm/install/#requirements[installation instructions] and noped right out of this one!

Ozone (above) is heavyweight enough; I'm sure both are great at what they do, but they are not a lightweight container to slot into my Docker Compose stack for local demos.

== Comparison

Everyone loves a bake-off chart, right?

[cols="1,1,1,2,1,1,1,1", options="header"]
|===
| Name | Ease of config | Licence | Commercial Backing & Governance | Docker pulls^1^ | GH Stars | Date of first commit | Significant Committers

| https://github.com/gaul/s3proxy[gaul/s3proxy]

(https://github.com/gaul/s3proxy[Git repo])
| üëçüëç
| Apache 2.0
| Single contributor (https://www.linkedin.com/in/agaul/[Andrew Gaul])
| https://hub.docker.com/r/andrewgaul/s3proxy/[5M+]
| https://github.com/gaul/s3proxy/stargazers[2.1k]
| 2014
| https://github.com/gaul/s3proxy/graphs/contributors[1]

| https://rustfs.com/[RustFS]

(https://github.com/rustfs/rustfs[Git repo])
| üëçüëç
| Apache 2.0
| https://docs.rustfs.com/about/[Fancy website but not much detail about the company]
| https://hub.docker.com/r/rustfs/rustfs[100k+]
| https://github.com/rustfs/rustfs/stargazers[19.7k]
| 2024
| https://github.com/rustfs/rustfs/graphs/contributors[~4]

| https://github.com/seaweedfs/seaweedfs/[SeaweedFS]

(https://github.com/seaweedfs/seaweedfs/[Git repo])
| üëç
| Apache 2.0
| Single contributor (https://github.com/chrislusf[Chris Lu]), https://seaweedfs.com/docs/pricing/[Enterprise option available]
| https://hub.docker.com/r/chrislusf/seaweedfs[5M+]
| https://github.com/seaweedfs/seaweedfs/stargazers[29.5k]
| 2012
| https://github.com/seaweedfs/seaweedfs/graphs/contributors[1]

| https://hub.docker.com/r/zenko/cloudserver/[Zenko CloudServer] (https://github.com/scality/cloudserver[Git repo])
| üëç
| Apache 2.0
| Scality (commercial company)
| https://hub.docker.com/r/zenko/cloudserver[5M+] (outdated version)
| https://github.com/scality/cloudserver/stargazers[1.9k]
| 2015
| https://github.com/scality/cloudserver/graphs/contributors[~10]

| https://garagehq.deuxfleurs.fr/[Garage]

(https://git.deuxfleurs.fr/Deuxfleurs/garage[Git repo])
| üò¨
| AGPL
| NGI/NLnet grants
| https://hub.docker.com/r/dxflrs/garage[1M+]
| https://github.com/deuxfleurs-org/garage/stargazers[2.5k]
| 2020
| https://git.deuxfleurs.fr/Deuxfleurs/garage/activity/contributors[~4]

| https://ozone.apache.org/[Apache Ozone]

(https://github.com/apache/ozone[Git repo])
| lol
| Apache 2.0
| Apache Software Foundation
| https://hub.docker.com/r/apache/ozone[1M+]
| https://github.com/apache/ozone/stargazers[1.1k]
| 2018
| https://github.com/apache/ozone/graphs/contributors[30+]

|===

^1^ Docker pulls is a useful signal but not an absolute one given that a small number of downstream projects using the image in a frequently-run CI/CD pipeline could easily distort this figure.

== Summary

I got side-tracked into writing this blog because I wanted to update a demo in which currently MinIO was used.
So, having tried them out, which of the options will I actually use?

* SeaweedFS - yes.
* S3Proxy - yes.
* RustFS - maybe, but very new project & alpha release.
* CloudServer - yes, maybe? Honestly, put off by it being part of a suite and worrying I'd need to understand other bits of it to use it‚Äîprobably unfounded though.
* Garage - no, config too complex for what I need.
* Apache Ozone - lol no.

I mean to cast no shade on those options against which I've not recorded a `yes`; they're probably excellent projects, but just not focussed on my primary use case (simple & easy to configure single-node local S3).

A few parting considerations to bear in mind when choosing a replacement for MinIO:

* **Governance**. Whilst all the projects are OSS, only Ozone is owned by a foundation (ASF). All the others could, _in theory_, change their licence at the drop of a hat (just like MinIO did).
* **Community health**. What's the "bus factor"? A couple of the projects above have a very long and healthy history‚Äîbut from a single contributor. If they were to abandon the project, would someone in the community fork and continue to actively develop it?

== Addendum

* 2026-01-30: Justin Cormack has written about some of the https://buttondown.com/justincormack/archive/ignore-previous-directions-10-new-rusty-object/[implementation details and functionality of RustFS and Garage]
