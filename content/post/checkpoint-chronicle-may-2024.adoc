---
title: 'Checkpoint Chronicle - May 2024'
date: "2024-05-28T00:00:00+00:00"
draft: false
credit: "https://bsky.app/profile/rmoff.net"
categories:
- Checkpoint Chronicle
image: "/images/2024/05/GOu6ytYXsAIODkF.jpg"
---

NOTE: This post originally appeared on the link:https://www.decodable.co/blog/checkpoint-chronicle-may-2024[Decodable blog].

Welcome to the _Checkpoint Chronicle_, a monthly roundup of interesting stuff in the data and streaming space.
Your hosts and esteemed curators of said content are  link:https://twitter.com/gunnarmorling?lang=en[Gunnar Morling]  and  link:https://twitter.com/rmoff/[Robin Moffatt]  (your editor-in-chief for this edition).
Feel free to send our way any choice nuggets that you think we should feature in future editions.

<!--more-->

=== Stream Processing, Streaming SQL, and Streaming Databases
* My favourite kind of blog post for learning about something is to actually build something with it‚Äîand Fredrik Meyer does a great job of this in his post here:  link:https://fredrikmeyer.net/2024/05/06/estimating-pi-kafka.html[Estimating Pi with Kafka Streams] .
* Apache Paimon is a lakehouse storage format (in the same vein as Apache Iceberg et al). It was spun out of the Apache Flink project originally and has a focus on streaming data. It  link:https://github.com/apache/paimon/issues/3091[graduated]  to a top-level Apache project earlier this year, and recently announced the introduction of a feature called  link:https://medium.com/@ipolyzos_/apache-paimon-introducing-deletion-vectors-584666ee90de[deletion vectors]  to improve the efficiency of reading and writing data.
* This is a good writeup of how you can  link:https://www.feldera.com/blog/eventbridge-and-feldera/[use SQL-based stream processing for SecOps analysis of real time S3 bucket access] . It‚Äôs built on  link:https://github.com/feldera/feldera[Feldera]  which is an open-source implementation of DBSP (see Papers, below).
* One of the things that can sometimes be frustrating about the melee of open-source projects is getting them to work well together, so I was pleased to see  link:https://lists.apache.org/thread/qhz17ppdbb57ql356j49qqk3nyk59rvm[this discussion]  and  link:https://github.com/apache/iceberg/pull/10179[progress]  on tighter support between Flink and Iceberg.
* An interesting account of some benchmarking that Yahoo did to look at  link:https://medium.com/google-cloud/yahoo-benchmarks-dataflow-vs-b189c809ff49?source=rss------apache_flink-5[the performance (from a cost point of view) difference between Apache Flink and Google Cloud Dataflow] .
* Flink has several sub-projects, including Flink ML. This blog post is based on a talk that was given at Flink Forward Asia last year about  link:https://www.alibabacloud.com/blog/analysis-and-application-of-new-features-of-flink-ml_601119[how Flink ML works and some of its new features] .


=== Event Streaming
* An excellent article about  link:https://medium.com/agoda-engineering/how-we-solve-load-balancing-challenges-in-apache-kafka-8cd88fdad02b[how Agoda analysed and solved performance problems they observed in their use of Apache Kafka] , focussing on topic partition load balancing strategies.
* WarpStream is one of the several Kafka-as-an-API providers that have emerged recently, and continue their interesting blog series with notes on  link:https://medium.com/@warpstream/cloud-disks-are-really-expensive-47ae765b32bb[Cloud Disk Costs]  and their opinion that  link:https://medium.com/@warpstream/tiered-storage-wont-fix-kafka-4b8ca34f2b8f[Tiered Storage Won‚Äôt Fix Kafka] .
* My former colleague Lucia Cerchie has a nice article on  link:https://www.confluent.io/blog/how-to-write-KIPs-for-apache-kafka/[how to write Kafka Improvement Proposals (KIPs] ), and I enjoyed reading Phuc Tran‚Äôs account of their experiences  link:https://medium.com/@phuctran3289/how-i-started-my-journey-on-contributing-to-apache-kafka-8a394664dab8[getting started contributing to Apache Kafka] .
* Adam Warski has written a superb explainer and analysis of  link:https://softwaremill.com/kafka-queues-now-and-in-the-future/[how queuing with Kafka can be problematic] , as well as discussing  link:https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A+Queues+for+Kafka[KIP-932]  which is intended to address this issue, plus offering a solution that‚Äôs available now called the ‚Äú link:https://softwaremill.com/kafka-with-selective-acknowledgments-performance/[KMQ] ‚Äù pattern.
* The problem of queues in Kafka caused CloudKitchens to ditch Kafka and develop  link:https://techblog.citystoragesystems.com/p/reliable-order-processing[their own technology for reliable order processing called KEQ] . There‚Äôs  link:https://old.reddit.com/r/apachekafka/comments/1cuc8ai/why_cloudkitchens_moved_away_from_kafka_for_order/[an interesting Reddit thread]  that accompanies the article.
* I‚Äôm always curious to see the kind of ‚Äúday 2‚Äù challenges that people encounter once they get past the ‚ÄúHello World‚Äù phase of implementation. This blog post from DoorDash is a thorough explanation of  link:https://doordash.engineering/2024/03/27/setting-up-kafka-multi-tenancy/[how they handle test/prod Kafka workloads and multi-tenancy] , including in some cases using the same Kafka cluster for both.


=== Data Platforms and Architecture
* Data Modeling goes in and out of fashion as technology enables people to crunch more data without needing it for pure optimisation alone‚Äîbut then people start getting wrong or confusing data, and realise that there‚Äôs a reason data modelling has been a thing for many decades. Joe Reiss is looking to raise its profile once more by writing a book about it and has shared excerpts from the  link:https://practicaldatamodeling.substack.com/p/practical-data-modeling-chapter-1[first]  and  link:https://practicaldatamodeling.substack.com/p/chapter-2-what-is-this-all-for[second]  chapters of Practical Data Modeling. Meanwhile, Adrian Bednarz writes about the  link:https://bednarzadrian.medium.com/is-star-schema-a-thing-in-2024-a-closer-look-at-the-obts-8ac747d7fe50[One Big Table (OBT) approach and its implications when doing stream processing] .
* An interesting explanation of how BackMarket are taking the opportunity during their migration onto GCP to  link:https://engineering.backmarket.com/how-we-expose-data-in-bigquery-2bac0244e2b9?source=rss----a2ffaa943221---4[apply some Data Mesh principles to how data is made available to their users] . It discusses the implementation from both a logical point of view, and the specific GCP tools used.
* It might not have the sparkle and allure of GenAI, but someone‚Äôs gotta do it‚Äîtaking the digital trash out. Netflix generates around 2 _Petabytes_ of data every week, of which it‚Äôs estimated that 40% is never used. This article goes into more detail and explains  link:https://netflixtechblog.medium.com/navigating-the-netflix-data-deluge-the-imperative-of-effective-data-management-e39af70f81f7[the tools and processes used to manage this data and its deletion when needed] .
* Canva describes how they hit scaling problems and ended up migrating from MySQL to  link:https://www.canva.dev/blog/engineering/scaling-to-count-billions/[Snowflake for an application responsible for counting usage] . One thing that struck me was no use of Kafka (or equivalent) for ingestion, and use of Snowflake to do the big crunching instead of Spark or Flink. I wonder how much of that is their existing familiarity with Snowflake (as mentioned in the article) vs it being more suitable for the job.


=== Change Data Capture
* link:https://medium.com/@ipolyzos_/a-glimpse-into-flink-cdc-3-0-a985fb5895a5[A good primer on Flink CDC 3.0]  which covers its architecture, APIs, and features including schema evolution.


=== Data Ecosystem
link:https://arrow.apache.org/blog/2024/05/07/datafusion-tlp/[Apache DataFusion recently became its own top level Apache project] , graduating out of being a part of Apache Arrow.
DataFusion is a query engine that can be used for building data systems.
It‚Äôs already found  link:https://datafusion.apache.org/user-guide/introduction.html#known-users[in many projects] , including an accelerator for Apache Spark called  link:https://datafusion.apache.org/comet/user-guide/overview.html[Comet] .

At its peak, Apache HBase held 6PB of data for Pinterest and underpinned many of their systems.
link:https://medium.com/pinterest-engineering/hbase-deprecation-at-pinterest-8a99e6c8e6b7?source=rss----4c5a5f6279b6---4[This article]  is a really well written account of their reasons for deciding to deprecate it in favour of tools including Apache Druid, and TiDB.

There‚Äôs a reason Chris Riccomini is featured often in Checkpoint Chronicle (I checked: five of the last six!)‚Äîhe writes really useful and pragmatic posts üòÄ.
This one looking at the  link:https://materializedview.io/p/nimble-and-lance-parquet-killers[Nimble and Lance file formats]  is no exception.
Whilst Parquet is going nowhere anytime soon, it‚Äôs interesting to look at the nebulous beginnings of what might one day replace it and why.

As well as Chris, I‚Äôm a big fanboi of Jack Vanlightly‚Äôs writing.
He has a knack for making the complex intelligible without dumbing it down.
His recent post on  link:https://jack-vanlightly.com/blog/2024/5/2/hybrid-transactional-analytical-storage[Hybrid Transactional/Analytical Storage]  is an interesting look at both Confluent‚Äôs strategy as well as the broader landscape for data platforms.

This one caught my eye, and I‚Äôll quote from the readme directly:  link:https://github.com/paradedb/paradedb/blob/ea729db69722aaacf9071086978fecf358d4340f/pg_lakehouse/README.md[pg_lakehouse]  is an extension that transforms Postgres into an analytical query engine over object stores like S3 and table formats like Apache Iceberg.
Queries are pushed down to Apache DataFusion.


=== Papers of the Month
* link:https://research.google/pubs/vortex-a-stream-oriented-storage-engine-for-big-data-analytics/[Vortex: A Stream-oriented Storage Engine For Big Data Analytics]
* link:https://www.feldera.com/vldb23.pdf[DBSP: Automatic Incremental View Maintenance for Rich Query Languages]


=== Events & Call for Papers (CfP)
link:https://program.berlinbuzzwords.de/bbuzz24/cfp[Berlin Buzzwords]  (Berlin, Germany) *June 9-11* (CfP closed)

link:https://current.confluent.io[Current '24 | The Next Generation of Kafka Summit]  (Austin, TX) *September 17-18* (CfP closed)

link:https://www.flink-forward.org/berlin-2024[Flink Forward]  (Berlin, Germany) *October 23-24* ( link:https://sessionize.com/flink-forward-2024-berlin[CfP]  extended, now closes on May 31)


=== New Releases
A few new releases this month:

* link:https://debezium.io/blog/2024/05/13/debezium-2-7-alpha2-released/[Debezium 2.7.0.Alpha2]
* link:https://flink.apache.org/2024/05/17/apache-flink-cdc-3.1.0-release-announcement/[Apache Flink CDC 3.1.0]
* link:https://paimon.apache.org/releases/release-0.8/[Apache Paimon 0.8]

That‚Äôs all for this month!
We hope you‚Äôve enjoyed the newsletter and would love to hear about any feedback or suggestions you‚Äôve got.

Gunnar ( link:https://de.linkedin.com/in/gunnar-morling-2b44b7229[LinkedIn]  /  link:https://twitter.com/gunnarmorling?lang=en[X]  /  link:https://mastodon.online/@gunnarmorling[Mastodon]  /  link:mailto:gunnar@decodable.co[Email] )

Robin ( link:https://www.linkedin.com/in/robinmoffatt[LinkedIn]  /  link:https://twitter.com/rmoff/[X]  /  link:https://data-folks.masto.host/@rmoff[Mastodon]  /  link:mailto:robin@decodable.co[Email] )